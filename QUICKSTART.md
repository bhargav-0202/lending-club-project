# Quick Start Guide

Get the Lending Club Loan Scoring project up and running in 5 minutes!

## Prerequisites

- Python 3.8 or higher
- Java 8+ (for Spark)

## Installation

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Prepare Your Data

Place your data files in `data/raw/`:
- `customers.csv`
- `loans.csv`
- `loans_repayments.csv`
- `loans_defaulters_delinq.csv`
- `loans_defaulters_detail.csv`

**Don't have data?** Check the `notebooks/` directory for example analysis.

## Run the Pipeline

### Option 1: Basic Usage (CSV Files)

```bash
python main.py
```

### Option 2: Hive Database

```bash
python main.py --hive
```

### Option 3: Custom Output Path

```bash
python main.py --output-path data/processed/my_scores
```

## What Happens

The pipeline will:

1. âœ… **Load** your data (CSV or Hive)
2. âœ… **Clean** data by removing duplicates and bad records
3. âœ… **Score** loans based on 3 criteria:
   - Payment History (20%)
   - Default History (45%)
   - Financial Health (35%)
4. âœ… **Grade** loans A through F
5. âœ… **Report** on grade distribution and risk analysis
6. âœ… **Save** results to `data/processed/loan_scores/`

## View Results

```python
import pandas as pd

# Load the results
scores = pd.read_parquet('data/processed/loan_scores/')

# See the first few
print(scores.head())

# Check grade distribution
print(scores['loan_final_grade'].value_counts())

# Analyze by grade
print(scores.groupby('loan_final_grade')['loan_score'].describe())
```

## Next Steps

- ğŸ“– Read [README.md](README.md) for comprehensive documentation
- ğŸ”§ Check [DEVELOPMENT.md](DEVELOPMENT.md) for development guide
- ğŸ““ Explore [notebooks/](notebooks/) for detailed analysis
- ğŸ§ª Review [src/](src/) modules for implementation details

## Troubleshooting

### No data files found

**Error**: "No data files found in data/raw directory"

**Solution**: Ensure CSV files are in `data/raw/` with correct names

### PySpark not installed

**Error**: "PySpark is not installed"

**Solution**: Run `pip install pyspark>=3.0.0`

### Out of memory

**Error**: Java heap space error

**Solution**: Increase memory
```bash
export SPARK_DRIVER_MEMORY=8g
export SPARK_EXECUTOR_MEMORY=8g
python main.py
```

### Data appears invalid

**Error**: Wrong column names or missing data

**Solution**: 
1. Check your CSV column names match the code expectations
2. Verify data types are correct
3. Check for missing values

## Project Structure

```
Lending-Club-Project/
â”œâ”€â”€ main.py                    # Entry point â­ RUN THIS
â”œâ”€â”€ README.md                  # Full documentation
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # ğŸ“¥ Put your data here
â”‚   â””â”€â”€ processed/             # ğŸ“¤ Results saved here
â”œâ”€â”€ src/                       # Core logic
â””â”€â”€ outputs/                   # Models and plots
```

## Learning Resources

- **Lending Club Dataset**: Public dataset with 900K+ loans
- **Spark**: Distributed processing for big data
- **Python ML**: scikit-learn for advanced models

## Support

Having issues? Check:

1. [README.md](README.md) - Comprehensive guide
2. [DEVELOPMENT.md](DEVELOPMENT.md) - Developer guide
3. Notebook examples in [notebooks/](notebooks/)
4. Source code docstrings in [src/](src/)

## Success! ğŸ‰

If you see this output, you're ready:

```
======================================================================
  PIPELINE EXECUTION COMPLETED
======================================================================

âœ“ Loan scoring completed successfully!
âœ“ Results saved to: data/processed/loan_scores
âœ“ Total loans scored: 10,000
```

Your loan scores are ready for analysis!
